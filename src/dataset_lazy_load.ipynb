{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset_id</th>\n",
       "      <th>dno_alias</th>\n",
       "      <th>aggregated_device_count_active</th>\n",
       "      <th>total_consumption_active_import</th>\n",
       "      <th>data_collection_log_timestamp</th>\n",
       "      <th>geometry</th>\n",
       "      <th>secondary_substation_unique_id</th>\n",
       "      <th>lv_feeder_unique_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NGED_110139_11_Dec_2024</td>\n",
       "      <td>NGED</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2107.0</td>\n",
       "      <td>2024-12-01 00:00:00+00:00</td>\n",
       "      <td>{'x': -2.5999, 'y': 51.4924}</td>\n",
       "      <td>NGED-110139</td>\n",
       "      <td>NGED-110139-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NGED_110139_12_Dec_2024</td>\n",
       "      <td>NGED</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1113.0</td>\n",
       "      <td>2024-12-01 00:00:00+00:00</td>\n",
       "      <td>{'x': -2.5999, 'y': 51.4924}</td>\n",
       "      <td>NGED-110139</td>\n",
       "      <td>NGED-110139-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NGED_110139_21_Dec_2024</td>\n",
       "      <td>NGED</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2471.0</td>\n",
       "      <td>2024-12-01 00:00:00+00:00</td>\n",
       "      <td>{'x': -2.5999, 'y': 51.4924}</td>\n",
       "      <td>NGED-110139</td>\n",
       "      <td>NGED-110139-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NGED_110139_23_Dec_2024</td>\n",
       "      <td>NGED</td>\n",
       "      <td>8.0</td>\n",
       "      <td>575.0</td>\n",
       "      <td>2024-12-01 00:00:00+00:00</td>\n",
       "      <td>{'x': -2.5999, 'y': 51.4924}</td>\n",
       "      <td>NGED-110139</td>\n",
       "      <td>NGED-110139-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NGED_110139_25_Dec_2024</td>\n",
       "      <td>NGED</td>\n",
       "      <td>31.0</td>\n",
       "      <td>3881.0</td>\n",
       "      <td>2024-12-01 00:00:00+00:00</td>\n",
       "      <td>{'x': -2.5999, 'y': 51.4924}</td>\n",
       "      <td>NGED-110139</td>\n",
       "      <td>NGED-110139-25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                dataset_id dno_alias  aggregated_device_count_active  \\\n",
       "0  NGED_110139_11_Dec_2024      NGED                            18.0   \n",
       "1  NGED_110139_12_Dec_2024      NGED                             8.0   \n",
       "2  NGED_110139_21_Dec_2024      NGED                            17.0   \n",
       "3  NGED_110139_23_Dec_2024      NGED                             8.0   \n",
       "4  NGED_110139_25_Dec_2024      NGED                            31.0   \n",
       "\n",
       "   total_consumption_active_import data_collection_log_timestamp  \\\n",
       "0                           2107.0     2024-12-01 00:00:00+00:00   \n",
       "1                           1113.0     2024-12-01 00:00:00+00:00   \n",
       "2                           2471.0     2024-12-01 00:00:00+00:00   \n",
       "3                            575.0     2024-12-01 00:00:00+00:00   \n",
       "4                           3881.0     2024-12-01 00:00:00+00:00   \n",
       "\n",
       "                       geometry secondary_substation_unique_id  \\\n",
       "0  {'x': -2.5999, 'y': 51.4924}                    NGED-110139   \n",
       "1  {'x': -2.5999, 'y': 51.4924}                    NGED-110139   \n",
       "2  {'x': -2.5999, 'y': 51.4924}                    NGED-110139   \n",
       "3  {'x': -2.5999, 'y': 51.4924}                    NGED-110139   \n",
       "4  {'x': -2.5999, 'y': 51.4924}                    NGED-110139   \n",
       "\n",
       "  lv_feeder_unique_id  \n",
       "0      NGED-110139-11  \n",
       "1      NGED-110139-12  \n",
       "2      NGED-110139-21  \n",
       "3      NGED-110139-23  \n",
       "4      NGED-110139-25  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lazy_df = dd.read_parquet(\"/Users/vaibhavsourirajan/Documents/COLUMBIA/Senior/WattCast/2024-12.parquet\")\n",
    "lazy_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total dataset size:  180401876\n",
      "Number of unique feeders:  122583\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset_id</th>\n",
       "      <th>dno_alias</th>\n",
       "      <th>aggregated_device_count_active</th>\n",
       "      <th>total_consumption_active_import</th>\n",
       "      <th>data_collection_log_timestamp</th>\n",
       "      <th>geometry</th>\n",
       "      <th>secondary_substation_unique_id</th>\n",
       "      <th>lv_feeder_unique_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NGED_110139_11_Dec_2024</td>\n",
       "      <td>NGED</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2107.0</td>\n",
       "      <td>2024-12-01 00:00:00+00:00</td>\n",
       "      <td>{'x': -2.5999, 'y': 51.4924}</td>\n",
       "      <td>NGED-110139</td>\n",
       "      <td>NGED-110139-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NGED_110139_12_Dec_2024</td>\n",
       "      <td>NGED</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1113.0</td>\n",
       "      <td>2024-12-01 00:00:00+00:00</td>\n",
       "      <td>{'x': -2.5999, 'y': 51.4924}</td>\n",
       "      <td>NGED-110139</td>\n",
       "      <td>NGED-110139-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NGED_110139_21_Dec_2024</td>\n",
       "      <td>NGED</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2471.0</td>\n",
       "      <td>2024-12-01 00:00:00+00:00</td>\n",
       "      <td>{'x': -2.5999, 'y': 51.4924}</td>\n",
       "      <td>NGED-110139</td>\n",
       "      <td>NGED-110139-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NGED_110139_23_Dec_2024</td>\n",
       "      <td>NGED</td>\n",
       "      <td>8.0</td>\n",
       "      <td>575.0</td>\n",
       "      <td>2024-12-01 00:00:00+00:00</td>\n",
       "      <td>{'x': -2.5999, 'y': 51.4924}</td>\n",
       "      <td>NGED-110139</td>\n",
       "      <td>NGED-110139-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NGED_110139_25_Dec_2024</td>\n",
       "      <td>NGED</td>\n",
       "      <td>31.0</td>\n",
       "      <td>3881.0</td>\n",
       "      <td>2024-12-01 00:00:00+00:00</td>\n",
       "      <td>{'x': -2.5999, 'y': 51.4924}</td>\n",
       "      <td>NGED-110139</td>\n",
       "      <td>NGED-110139-25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                dataset_id dno_alias  aggregated_device_count_active  \\\n",
       "0  NGED_110139_11_Dec_2024      NGED                            18.0   \n",
       "1  NGED_110139_12_Dec_2024      NGED                             8.0   \n",
       "2  NGED_110139_21_Dec_2024      NGED                            17.0   \n",
       "3  NGED_110139_23_Dec_2024      NGED                             8.0   \n",
       "4  NGED_110139_25_Dec_2024      NGED                            31.0   \n",
       "\n",
       "   total_consumption_active_import data_collection_log_timestamp  \\\n",
       "0                           2107.0     2024-12-01 00:00:00+00:00   \n",
       "1                           1113.0     2024-12-01 00:00:00+00:00   \n",
       "2                           2471.0     2024-12-01 00:00:00+00:00   \n",
       "3                            575.0     2024-12-01 00:00:00+00:00   \n",
       "4                           3881.0     2024-12-01 00:00:00+00:00   \n",
       "\n",
       "                       geometry secondary_substation_unique_id  \\\n",
       "0  {'x': -2.5999, 'y': 51.4924}                    NGED-110139   \n",
       "1  {'x': -2.5999, 'y': 51.4924}                    NGED-110139   \n",
       "2  {'x': -2.5999, 'y': 51.4924}                    NGED-110139   \n",
       "3  {'x': -2.5999, 'y': 51.4924}                    NGED-110139   \n",
       "4  {'x': -2.5999, 'y': 51.4924}                    NGED-110139   \n",
       "\n",
       "  lv_feeder_unique_id  \n",
       "0      NGED-110139-11  \n",
       "1      NGED-110139-12  \n",
       "2      NGED-110139-21  \n",
       "3      NGED-110139-23  \n",
       "4      NGED-110139-25  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "london_bbox = (-0.6, 51.4, 0.4, 51.7)\n",
    "london_df = dd.read_parquet(\"/Users/vaibhavsourirajan/Documents/COLUMBIA/Senior/WattCast/2024-12.parquet\", bbox=london_bbox)\n",
    "print(\"Total dataset size: \", len(london_df))\n",
    "print(\"Number of unique feeders: \", len(london_df[\"lv_feeder_unique_id\"].unique()))\n",
    "\n",
    "london_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to convert partition to expected pyarrow schema:\n    `ArrowTypeError(\"Expected bytes, got a 'dict' object\", 'Conversion failed for column geometry with type object')`\n\nExpected partition schema:\n    dataset_id: large_string\n    dno_alias: large_string\n    aggregated_device_count_active: int64\n    total_consumption_active_import: int64\n    data_collection_log_timestamp: timestamp[ms, tz=UTC]\n    geometry: string\n    secondary_substation_unique_id: large_string\n    lv_feeder_unique_id: large_string\n    __null_dask_index__: int64\n\nReceived partition schema:\n    dataset_id: large_string\n    dno_alias: large_string\n    aggregated_device_count_active: double\n    total_consumption_active_import: double\n    data_collection_log_timestamp: timestamp[ms, tz=UTC]\n    geometry: struct<x: double, y: double>\n      child 0, x: double\n      child 1, y: double\n    secondary_substation_unique_id: large_string\n    lv_feeder_unique_id: large_string\n    __null_dask_index__: int64\n\nThis error *may* be resolved by passing in schema information for\nthe mismatched column(s) using the `schema` keyword in `to_parquet`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 16\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Save with explicit schema\u001b[39;00m\n\u001b[1;32m     11\u001b[0m london_df\u001b[38;5;241m.\u001b[39mto_parquet(\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlondon_dec_2024.parquet\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     13\u001b[0m     schema\u001b[38;5;241m=\u001b[39mschema\n\u001b[1;32m     14\u001b[0m )\n\u001b[0;32m---> 16\u001b[0m \u001b[43mlondon_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_parquet\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlondon_dec_2024.parquet\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mschema_coerce_strings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# This will coerce string columns to regular strings\u001b[39;49;00m\n\u001b[1;32m     19\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/wattcast/lib/python3.10/site-packages/dask/dataframe/dask_expr/_collection.py:3316\u001b[0m, in \u001b[0;36mDataFrame.to_parquet\u001b[0;34m(self, path, **kwargs)\u001b[0m\n\u001b[1;32m   3313\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto_parquet\u001b[39m(\u001b[38;5;28mself\u001b[39m, path, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   3314\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataframe\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdask_expr\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparquet\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m to_parquet\n\u001b[0;32m-> 3316\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mto_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/wattcast/lib/python3.10/site-packages/dask/dataframe/dask_expr/io/parquet.py:662\u001b[0m, in \u001b[0;36mto_parquet\u001b[0;34m(df, path, compression, write_index, append, overwrite, ignore_divisions, partition_on, storage_options, custom_metadata, write_metadata_file, compute, compute_kwargs, schema, name_function, filesystem, engine, **kwargs)\u001b[0m\n\u001b[1;32m    638\u001b[0m         out \u001b[38;5;241m=\u001b[39m new_collection(\n\u001b[1;32m    639\u001b[0m             ToParquet(\n\u001b[1;32m    640\u001b[0m                 df,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    658\u001b[0m             )\n\u001b[1;32m    659\u001b[0m         )\n\u001b[1;32m    661\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compute:\n\u001b[0;32m--> 662\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mout\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcompute_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    664\u001b[0m \u001b[38;5;66;03m# Invalidate the filesystem listing cache for the output path after write.\u001b[39;00m\n\u001b[1;32m    665\u001b[0m \u001b[38;5;66;03m# We do this before returning, even if `compute=False`. This helps ensure\u001b[39;00m\n\u001b[1;32m    666\u001b[0m \u001b[38;5;66;03m# that reading files that were just written succeeds.\u001b[39;00m\n\u001b[1;32m    667\u001b[0m fs\u001b[38;5;241m.\u001b[39minvalidate_cache(path)\n",
      "File \u001b[0;32m~/miniconda3/envs/wattcast/lib/python3.10/site-packages/dask/dataframe/dask_expr/_collection.py:491\u001b[0m, in \u001b[0;36mFrameBase.compute\u001b[0;34m(self, fuse, concatenate, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m     out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mrepartition(npartitions\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    490\u001b[0m out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39moptimize(fuse\u001b[38;5;241m=\u001b[39mfuse)\n\u001b[0;32m--> 491\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDaskMethodsMixin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/wattcast/lib/python3.10/site-packages/dask/base.py:370\u001b[0m, in \u001b[0;36mDaskMethodsMixin.compute\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    347\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute this dask collection\u001b[39;00m\n\u001b[1;32m    348\u001b[0m \n\u001b[1;32m    349\u001b[0m \u001b[38;5;124;03m    This turns a lazy Dask collection into its in-memory equivalent.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[38;5;124;03m    dask.compute\u001b[39;00m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 370\u001b[0m     (result,) \u001b[38;5;241m=\u001b[39m \u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraverse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    371\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/miniconda3/envs/wattcast/lib/python3.10/site-packages/dask/base.py:656\u001b[0m, in \u001b[0;36mcompute\u001b[0;34m(traverse, optimize_graph, scheduler, get, *args, **kwargs)\u001b[0m\n\u001b[1;32m    653\u001b[0m     postcomputes\u001b[38;5;241m.\u001b[39mappend(x\u001b[38;5;241m.\u001b[39m__dask_postcompute__())\n\u001b[1;32m    655\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m shorten_traceback():\n\u001b[0;32m--> 656\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mschedule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdsk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    658\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m repack([f(r, \u001b[38;5;241m*\u001b[39ma) \u001b[38;5;28;01mfor\u001b[39;00m r, (f, a) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(results, postcomputes)])\n",
      "File \u001b[0;32m~/miniconda3/envs/wattcast/lib/python3.10/site-packages/dask/dataframe/io/parquet/core.py:158\u001b[0m, in \u001b[0;36mToParquetFunctionWrapper.__call__\u001b[0;34m(self, df, block_index)\u001b[0m\n\u001b[1;32m    151\u001b[0m filename \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpart.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpart_i\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mi_offset\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.parquet\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    153\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname_function \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname_function(part_i \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mi_offset)\n\u001b[1;32m    155\u001b[0m )\n\u001b[1;32m    157\u001b[0m \u001b[38;5;66;03m# Write out data\u001b[39;00m\n\u001b[0;32m--> 158\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_partition\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpartition_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_metadata_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs_pass\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhead\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpart_i\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs_pass\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/wattcast/lib/python3.10/site-packages/dask/dataframe/io/parquet/arrow.py:825\u001b[0m, in \u001b[0;36mArrowDatasetEngine.write_partition\u001b[0;34m(cls, df, path, fs, filename, partition_on, return_metadata, fmd, compression, index_cols, schema, head, custom_metadata, **kwargs)\u001b[0m\n\u001b[1;32m    822\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    823\u001b[0m     index_cols \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 825\u001b[0m t \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pandas_to_arrow_table\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreserve_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreserve_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    826\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m custom_metadata:\n\u001b[1;32m    827\u001b[0m     _md \u001b[38;5;241m=\u001b[39m t\u001b[38;5;241m.\u001b[39mschema\u001b[38;5;241m.\u001b[39mmetadata\n",
      "File \u001b[0;32m~/miniconda3/envs/wattcast/lib/python3.10/site-packages/dask/dataframe/io/parquet/arrow.py:786\u001b[0m, in \u001b[0;36mArrowDatasetEngine._pandas_to_arrow_table\u001b[0;34m(cls, df, preserve_index, schema)\u001b[0m\n\u001b[1;32m    780\u001b[0m expected \u001b[38;5;241m=\u001b[39m textwrap\u001b[38;5;241m.\u001b[39mindent(\n\u001b[1;32m    781\u001b[0m     schema\u001b[38;5;241m.\u001b[39mto_string(show_schema_metadata\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    782\u001b[0m )\n\u001b[1;32m    783\u001b[0m actual \u001b[38;5;241m=\u001b[39m textwrap\u001b[38;5;241m.\u001b[39mindent(\n\u001b[1;32m    784\u001b[0m     df_schema\u001b[38;5;241m.\u001b[39mto_string(show_schema_metadata\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    785\u001b[0m )\n\u001b[0;32m--> 786\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    787\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to convert partition to expected pyarrow schema:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    788\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexc\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m`\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    789\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    790\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected partition schema:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    791\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexpected\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    792\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    793\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived partition schema:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    794\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mactual\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    795\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    796\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis error *may* be resolved by passing in schema information for\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    797\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe mismatched column(s) using the `schema` keyword in `to_parquet`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    798\u001b[0m ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Failed to convert partition to expected pyarrow schema:\n    `ArrowTypeError(\"Expected bytes, got a 'dict' object\", 'Conversion failed for column geometry with type object')`\n\nExpected partition schema:\n    dataset_id: large_string\n    dno_alias: large_string\n    aggregated_device_count_active: int64\n    total_consumption_active_import: int64\n    data_collection_log_timestamp: timestamp[ms, tz=UTC]\n    geometry: string\n    secondary_substation_unique_id: large_string\n    lv_feeder_unique_id: large_string\n    __null_dask_index__: int64\n\nReceived partition schema:\n    dataset_id: large_string\n    dno_alias: large_string\n    aggregated_device_count_active: double\n    total_consumption_active_import: double\n    data_collection_log_timestamp: timestamp[ms, tz=UTC]\n    geometry: struct<x: double, y: double>\n      child 0, x: double\n      child 1, y: double\n    secondary_substation_unique_id: large_string\n    lv_feeder_unique_id: large_string\n    __null_dask_index__: int64\n\nThis error *may* be resolved by passing in schema information for\nthe mismatched column(s) using the `schema` keyword in `to_parquet`."
     ]
    }
   ],
   "source": [
    "#save the dataframe to a csv file\n",
    "\n",
    "import pyarrow as pa\n",
    "\n",
    "schema = pa.schema([\n",
    "    ('lv_feeder_unique_id', pa.string()),\n",
    "    # Add other columns as needed with their appropriate types\n",
    "])\n",
    "\n",
    "# Save with explicit schema\n",
    "london_df.to_parquet(\n",
    "    \"london_dec_2024.parquet\",\n",
    "    schema=schema\n",
    ")\n",
    "\n",
    "london_df.to_parquet(\n",
    "    \"london_dec_2024.parquet\",\n",
    "    schema_coerce_strings=True  # This will coerce string columns to regular strings\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
